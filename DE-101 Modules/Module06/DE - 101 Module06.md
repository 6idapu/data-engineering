# Модуль 6:  Аналитические Хранилища Данных

[Обратно в содержание курса :leftwards_arrow_with_hook:](https://github.com/Data-Learn/data-engineering/blob/master/DE%20-%20101%20Guide.md) 

В 6 модуле мы узнаем про аналитические и облачные хранилища данных которые используются в индустрии. Крупные компания Amazon, Microsoft, Airbnb, и многие другие из списка SP500 используют одну или сразу несколько решений для аналитических хранилищ данных - Amazon Redshift, Microsoft Synapse, Google BigQuery или Snowflake. Но кроме облачных хранилищ есть еще много on-premise Teradata, Greenplum, Vertica, Exasol и тп. 

Из модуля вы узнаете:
- Основы аналитических хранилищ данных
- MPP vs SMP
- Практика с Redshift, Snowflake и Azure Synapse
- Облачные ETL инструменты
- Обзор вакансий мирового рынка
- Обзор решений для операционной аналитики - Splunk, Azure Data Explorer и ElasticSearch

## Модуль 6.1 Введение

**Видео лекция - теория** - [Введение](https://youtu.be/yxNjsrePuqo). 

## Модуль 6.2 Что Такое Аналитическое Хранилище Данных?
В 95 процентах аналитических решений используется хранилище данных. Давайте будем считать, что это аналитическое хранилище данных. Но что это такое? Какие они бывают? Как давно они на рынке? На эти вопросы и другие я отвечу в это уроке. 

На этом уроке мы посмотрим фундаментыльные вещи про хранилище данных, а на последующих уроках, мы будем уже пробовать различные решения хранилищ данных и ETL/ELT инструментов.  Практически каждый слайд можно трансформировать в вопрос для собеседования, и я сам, нераз, спрашивал на собеседованиях в Амазон эти вопросы на позицию инженера данных и bi разработчика.

Из модуля вы узнаете:
- История хранилищ данных
- База данных vs Хранилище данных
- Хранилище данных (DW) vs Платформа данных
- Характеристики хранилища данных
- Архитектура Shared Nothing vs Shared Everything
- Cloud vs On-premise Хранилища данных
- Облачная экономика на примере ETL jobs
- Open Source vs Commercial Хранилища данных
- Хранилища данных на базе существующей технологии (Postgres) или свои разработки
- Data warehouse as a Service или в ручную тюнить
- Современные и Legacy Хранилища данных
- OLTP vs OLAP
- ETL vs ELT
- Вендоры Хранилища данных на рынке (Gartner and Forrester)
- Сравнение скорости - benchmarking - TPC
- Benchmarking, отчет Gigaom и Fivetran по облачных хранилищам данных
- История Teradata
- Основы MPP Teradata, Data Distribution, Data Skew и Teradata CLI

**Видео лекция - теория** - [Введение](https://youtu.be/JuQCUGUWqgU). 

### Дополнительные материалы для изучения
- [Отчет по Gigaom DW Benchmarking](https://gigaom.com/report/data-warehouse-cloud-benchmark/)
- [Отчет Fivetran по DW Benchmarking](https://fivetran.com/blog/warehouse-benchmark)
- Интерсный и большой курс по Data Warehouse на Coursera

Интересные статьи по теме (необязательно все читать, но можно ознакомиться, теперь вы точно будете знать ключевые слова по теме)
- [Что такое Teradata?](https://habr.com/ru/post/209078/)
- [Поколоночное и гибридное хранение записей в СУБД Teradata](https://habr.com/ru/company/teradata/blog/170321/)
- [Oracle vs Teradata vs Hadoop](https://habr.com/ru/post/235465/)
- [Из нагруженной MPP СУБД — бодрый Data Lake с аналитическими инструментами: делимся подробностями создания](https://habr.com/ru/company/vtb/blog/420141/)
- [Колоночные СУБД — принцип действия, преимущества и область применения](https://habr.com/ru/post/95181/)
- [Сравнение аналитических in-memory баз данных](https://habr.com/ru/company/tinkoff/blog/310620/)
- [Колоночные СУБД против строчных, как насчет компромисса?](https://habr.com/ru/post/413051/)
- [Тестирование производительности Oracle In-Memory Option c использованием TPC-H Benchmark](https://habr.com/ru/post/317774/)
- [HP Vertica, первый запущенный проект в РФ, опыт полтора года реальной эксплуатации](https://habr.com/ru/post/190740/)
- [Business Intelligence на очень больших данных: опыт Yota](https://habr.com/ru/company/yota/blog/541266/)
- [HP Vertica, проектирование хранилища данных, больших данных](https://habr.com/ru/post/227111/)
- [Просто и доступно о аналитических БД](https://habr.com/ru/post/149641/)

### Лабораторная работа
На лабораторной работе вы будете использовать виртуальную мащину Teradata DW, вам нужно будет скачать ее и настроить доступ через конфигурацию сети. Дальше вы сможете загрузать данные через CLI инструмент и подключить Power BI. Таким образом у вас будет полноценное аналитическое решение (портативное), которое работает во многих компаниях.

**Видео лекция - практика** - [Введение](https://youtu.be/JuQCUGUWqgU?t=2766). 

[Ссылка на лабораторную работу к модулю 6.2](https://github.com/Data-Learn/data-engineering/blob/master/DE-101%20Modules/Module06/DE%20-%20101%20Labs/Teradata/Teradata%20Lab.md)

### Опциональное задание:
Вы можете использовать Pentaho DI, чтобы добавить ETL компомент в ваше аналитическое решение. Попробуйте реализовать задание из модуля 4 (любое или все).


## Модуль 6.3 Основы Amazon Redshift



### Дополнительные материалы для изучения



### Лабораторная Работа

 

## Модуль 6.4 Основы Azure Synapse для Хранилища данных



### Дополнительные материалы для изучения



### Практика


### Лабораторная Работа


## Модуль 6.5 Основы Snowflake


## Дополнительные материалы для изучения

### Лабораторная Работа

## Модуль 6.6 Обзор современных ETL/ELT инструментов

### Дополнительные материалы для изучения

### Практика


## Модуль 6.7 Обзор профессий и требований


### Дополнительные материалы для изучения



По окончанию модуля 6, вы можете расшарить значок `06 | Cloud DW` в социальных сетях и рассказать о своих достижениях. 

![img]()

А также добавить в Linkedin сертификат:

![img]()
Все доступные сертификаты можете посмотреть в этом [linkedin профайле](https://www.linkedin.com/in/lana-naumova-8a1b78171/).


PS Если материал оказался полезным, вы можете поддержать авторов через 
[ЮMoney](https://yoomoney.ru/to/4100116864248269) или [Patreon](https://www.patreon.com/dmitryanoshin) или [Paypal](https://paypal.me/dmitryanoshin)

